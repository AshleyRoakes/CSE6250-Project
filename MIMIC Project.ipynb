{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a331de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk import word_tokenize\n",
    "from nltk.internals import find_jars_within_path\n",
    "import nltk\n",
    "import sklearn.model_selection\n",
    "from collections import Counter\n",
    "import sklearn.feature_extraction.text as skt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "#import torch\n",
    "#import transformers\n",
    "\n",
    "import pyhealth\n",
    "from pyhealth.medcode import InnerMap\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as STOP_WORDS\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import gensim.models.word2vec as w2v\n",
    "\n",
    "#from transformers import AutoTokenizer, AutoModel\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "#model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import torch\n",
    "# from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c542936",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/ashleyroakes/Desktop/\"\n",
    "#root = \"C:/Users/mab28/Documents/Workspace/School/CSE 6250 Big Data Health/project/our_code/data/\"\n",
    "\n",
    "mim_root = root + \"mimic-iii-clinical-database-1.4/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b7b726",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "## Read in Discharge Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9078a11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-44e46582d5d0>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  notes_df = pd.read_csv(notes, compression='gzip', error_bad_lines=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discharge summaries:  55177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22532</td>\n",
       "      <td>167853.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13702</td>\n",
       "      <td>107527.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13702</td>\n",
       "      <td>167118.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13702</td>\n",
       "      <td>196489.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26880</td>\n",
       "      <td>135453.0</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID   HADM_ID           CATEGORY DESCRIPTION  \\\n",
       "0       22532  167853.0  Discharge summary      Report   \n",
       "1       13702  107527.0  Discharge summary      Report   \n",
       "2       13702  167118.0  Discharge summary      Report   \n",
       "3       13702  196489.0  Discharge summary      Report   \n",
       "4       26880  135453.0  Discharge summary      Report   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
       "2  Admission Date:  [**2119-5-4**]              D...  \n",
       "3  Admission Date:  [**2124-7-21**]              ...  \n",
       "4  Admission Date:  [**2162-3-3**]              D...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = mim_root + \"NOTEEVENTS.csv.gz\"\n",
    "\n",
    "notes_df = pd.read_csv(notes, compression='gzip', error_bad_lines=False, \n",
    "                       usecols = ['SUBJECT_ID', 'HADM_ID', 'CATEGORY', 'DESCRIPTION','TEXT'])\\\n",
    "                      .query(\"CATEGORY == 'Discharge summary'\")\\\n",
    "                      .query(\"DESCRIPTION == 'Report'\")\n",
    "\n",
    "# Should be 55,177 records\n",
    "print(\"Number of discharge summaries: \", + len(notes_df))\n",
    "\n",
    "notes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757857a9",
   "metadata": {},
   "source": [
    "## Read in Patient Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16993f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-9a3e874e7dee>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  diag_df = pd.read_csv(diag, compression='gzip', error_bad_lines=False)\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>[25013, 3371, 5849, 5780, V5867, 25063, 5363, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>[53100, 2851, 07054, 5715, 45621, 53789, 4019,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006</td>\n",
       "      <td>[49320, 51881, 486, 20300, 2761, 7850, 3090, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100007</td>\n",
       "      <td>[56081, 5570, 9973, 486, 4019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009</td>\n",
       "      <td>[41401, 99604, 4142, 25000, 27800, V8535, 4148...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID                                          ICD9_CODE\n",
       "0   100001  [25013, 3371, 5849, 5780, V5867, 25063, 5363, ...\n",
       "1   100003  [53100, 2851, 07054, 5715, 45621, 53789, 4019,...\n",
       "2   100006  [49320, 51881, 486, 20300, 2761, 7850, 3090, V...\n",
       "3   100007                     [56081, 5570, 9973, 486, 4019]\n",
       "4   100009  [41401, 99604, 4142, 25000, 27800, V8535, 4148..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag = mim_root + \"DIAGNOSES_ICD.csv.gz\"\n",
    "\n",
    "diag_df = pd.read_csv(diag, compression='gzip', error_bad_lines=False)\\\n",
    "                    .dropna()\\\n",
    "                    .groupby('HADM_ID')['ICD9_CODE']\\\n",
    "                    .unique()\\\n",
    "                    .reset_index()\n",
    "\n",
    "diag_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befa018",
   "metadata": {},
   "source": [
    "## Read in ICD9 Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e7e3472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-fb0e33a27e31>:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  icd_df = pd.read_csv(icd, compression='gzip', error_bad_lines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>SHORT_TITLE</th>\n",
       "      <th>LONG_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>01166</td>\n",
       "      <td>TB pneumonia-oth test</td>\n",
       "      <td>Tuberculous pneumonia [any form], tubercle bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>01170</td>\n",
       "      <td>TB pneumothorax-unspec</td>\n",
       "      <td>Tuberculous pneumothorax, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>01171</td>\n",
       "      <td>TB pneumothorax-no exam</td>\n",
       "      <td>Tuberculous pneumothorax, bacteriological or h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>01172</td>\n",
       "      <td>TB pneumothorx-exam unkn</td>\n",
       "      <td>Tuberculous pneumothorax, bacteriological or h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>01173</td>\n",
       "      <td>TB pneumothorax-micro dx</td>\n",
       "      <td>Tuberculous pneumothorax, tubercle bacilli fou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID ICD9_CODE               SHORT_TITLE  \\\n",
       "0     174     01166     TB pneumonia-oth test   \n",
       "1     175     01170    TB pneumothorax-unspec   \n",
       "2     176     01171   TB pneumothorax-no exam   \n",
       "3     177     01172  TB pneumothorx-exam unkn   \n",
       "4     178     01173  TB pneumothorax-micro dx   \n",
       "\n",
       "                                          LONG_TITLE  \n",
       "0  Tuberculous pneumonia [any form], tubercle bac...  \n",
       "1              Tuberculous pneumothorax, unspecified  \n",
       "2  Tuberculous pneumothorax, bacteriological or h...  \n",
       "3  Tuberculous pneumothorax, bacteriological or h...  \n",
       "4  Tuberculous pneumothorax, tubercle bacilli fou...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icd = mim_root + \"D_ICD_DIAGNOSES.csv.gz\"\n",
    "icd_df = pd.read_csv(icd, compression='gzip', error_bad_lines=False)\n",
    "\n",
    "\n",
    "icd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d7502",
   "metadata": {},
   "source": [
    "## Merge datasets by HADM_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8a4e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55172"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(diag_df, notes_df, on='HADM_ID', how='inner')\n",
    "\n",
    "# Should be 55177-5 = 55172\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193cbba",
   "metadata": {},
   "source": [
    "## Substitute special sequences & Filter HoPI sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb0055",
   "metadata": {},
   "source": [
    "### Identify HOPI sections & Substitute Special Sequences: These special sequences were identified and replaced by the first token in the sequence, e.g. \"[**Hospital1 18**]\" was replaced by ‘Hospital1’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f357cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_notes(st):\n",
    "    s  = \"History of Present Illness\"\n",
    "    s1 = \"HISTORY OF PRESENT ILLNESS|HISTORY OF THE PRESENT ILLNESS|\\nHISTORY:|present illness|Present Illness|PRESENT ILLNESS\"\n",
    "    \n",
    "    match  = re.search(s, st)\n",
    "    match1 = re.search(s1, st)\n",
    "    \n",
    "    if (match is not None) or (match1 is not None):\n",
    "        if match is not None:\n",
    "            st = st.split(s, 1)[1]\n",
    "            e = \"\\n\\n\\n\"\n",
    "            n = st.split(e, 1)[0]\n",
    "    \n",
    "        elif match1 is not None: \n",
    "            st = st.split(match1[0], 1)[1]\n",
    "            e = re.search(r\"\\n[\\s\\w]+:\", st)[0]\n",
    "            n = st.split(e, 1)[0]\n",
    "        \n",
    "        # Replace special strings with \"\"\n",
    "        rep = re.findall(r\"\\[\\*\\*([a-zA-Z0-9]*)\", n)\n",
    "        strt = [m.start() for m in re.finditer(\"\\[\\*\\*([a-zA-Z0-9]*)\", n)]\n",
    "        end = [m.end() for m in re.finditer(\"([a-zA-Z0-9]*)\\*\\*\\]\", n)]\n",
    "\n",
    "        for i in range(len(rep)):\n",
    "            n = n[:strt[i]] + rep[i] + \" \" + n[end[i] + 1:]\n",
    "        \n",
    "    else: \n",
    "        n = ''\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "991b1670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs missing HOPI sections:1867\n"
     ]
    }
   ],
   "source": [
    "df['HOPI'] = df[\"TEXT\"].map(lambda t: process_notes(t))\n",
    "\n",
    "# Detect history of present illness in text (n = 2641 records without HoPI data)\n",
    "missing = len(df[df['HOPI'] == \"\"])\n",
    "print(\"Number of docs missing HOPI sections: \" + str(missing))\n",
    "\n",
    "df = df[df[\"HOPI\"] != \"\"].reset_index(drop = True)\n",
    "\n",
    "df['SENT_TOKENS'] = df[\"HOPI\"].map(lambda t: [p.lower() for p in nltk.RegexpTokenizer(r'\\w+').tokenize(t) if not p.isnumeric()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a132416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>HOPI</th>\n",
       "      <th>SENT_TOKENS</th>\n",
       "      <th>SENT_TOKENS_COMBO</th>\n",
       "      <th>trunc_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>[25013, 3371, 5849, 5780, V5867, 25063, 5363, ...</td>\n",
       "      <td>58526</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2117-9-11**]              ...</td>\n",
       "      <td>:\\n35F w/ poorly controlled Type 1 diabetes me...</td>\n",
       "      <td>[325mg, 35f, 3l, 3rd, 4mg, 5d, a, ag, also, am...</td>\n",
       "      <td>325mg 35f 3l 3rd 4mg 5d a ag also am an and an...</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>[53100, 2851, 07054, 5715, 45621, 53789, 4019,...</td>\n",
       "      <td>54610</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2150-4-17**]              ...</td>\n",
       "      <td>:\\nMr. Known is a 59M w HepC cirrhosis c/b gra...</td>\n",
       "      <td>[40mg, 4l, 59m, a, abdominal, about, abstain, ...</td>\n",
       "      <td>40mg 4l 59m a abdominal about abstain admissio...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006</td>\n",
       "      <td>[49320, 51881, 486, 20300, 2761, 7850, 3090, V...</td>\n",
       "      <td>9895</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2108-4-6**]       Discharg...</td>\n",
       "      <td>:  This is a 48 year old African\\nAmerican fem...</td>\n",
       "      <td>[a, abdominal, abg, admitted, african, ago, al...</td>\n",
       "      <td>a abdominal abg admitted african ago albuterol...</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100007</td>\n",
       "      <td>[56081, 5570, 9973, 486, 4019]</td>\n",
       "      <td>23018</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2145-3-31**]              ...</td>\n",
       "      <td>:\\nMs Known is a 73 year old female with a his...</td>\n",
       "      <td>[a, abdominal, and, appendectomy, back, began,...</td>\n",
       "      <td>a abdominal and appendectomy back began bowel ...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009</td>\n",
       "      <td>[41401, 99604, 4142, 25000, 27800, V8535, 4148...</td>\n",
       "      <td>533</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>Admission Date:  [**2162-5-16**]              ...</td>\n",
       "      <td>:\\n60yo man with known coronary disease (AMI i...</td>\n",
       "      <td>[36mmhg, 60yo, a, admitted, ak, ami, and, angi...</td>\n",
       "      <td>36mmhg 60yo a admitted ak ami and angina anter...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID                                          ICD9_CODE  SUBJECT_ID  \\\n",
       "0   100001  [25013, 3371, 5849, 5780, V5867, 25063, 5363, ...       58526   \n",
       "1   100003  [53100, 2851, 07054, 5715, 45621, 53789, 4019,...       54610   \n",
       "2   100006  [49320, 51881, 486, 20300, 2761, 7850, 3090, V...        9895   \n",
       "3   100007                     [56081, 5570, 9973, 486, 4019]       23018   \n",
       "4   100009  [41401, 99604, 4142, 25000, 27800, V8535, 4148...         533   \n",
       "\n",
       "            CATEGORY DESCRIPTION  \\\n",
       "0  Discharge summary      Report   \n",
       "1  Discharge summary      Report   \n",
       "2  Discharge summary      Report   \n",
       "3  Discharge summary      Report   \n",
       "4  Discharge summary      Report   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0  Admission Date:  [**2117-9-11**]              ...   \n",
       "1  Admission Date:  [**2150-4-17**]              ...   \n",
       "2  Admission Date:  [**2108-4-6**]       Discharg...   \n",
       "3  Admission Date:  [**2145-3-31**]              ...   \n",
       "4  Admission Date:  [**2162-5-16**]              ...   \n",
       "\n",
       "                                                HOPI  \\\n",
       "0  :\\n35F w/ poorly controlled Type 1 diabetes me...   \n",
       "1  :\\nMr. Known is a 59M w HepC cirrhosis c/b gra...   \n",
       "2  :  This is a 48 year old African\\nAmerican fem...   \n",
       "3  :\\nMs Known is a 73 year old female with a his...   \n",
       "4  :\\n60yo man with known coronary disease (AMI i...   \n",
       "\n",
       "                                         SENT_TOKENS  \\\n",
       "0  [325mg, 35f, 3l, 3rd, 4mg, 5d, a, ag, also, am...   \n",
       "1  [40mg, 4l, 59m, a, abdominal, about, abstain, ...   \n",
       "2  [a, abdominal, abg, admitted, african, ago, al...   \n",
       "3  [a, abdominal, and, appendectomy, back, began,...   \n",
       "4  [36mmhg, 60yo, a, admitted, ak, ami, and, angi...   \n",
       "\n",
       "                                   SENT_TOKENS_COMBO  trunc_len  \n",
       "0  325mg 35f 3l 3rd 4mg 5d a ag also am an and an...        212  \n",
       "1  40mg 4l 59m a abdominal about abstain admissio...        300  \n",
       "2  a abdominal abg admitted african ago albuterol...        231  \n",
       "3  a abdominal and appendectomy back began bowel ...         71  \n",
       "4  36mmhg 60yo a admitted ak ami and angina anter...        130  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truncate then tokenize\n",
    "df[\"SENT_TOKENS\"] = df[\"SENT_TOKENS\"].map(lambda c: np.unique(c)[0:500])\n",
    "\n",
    "df['SENT_TOKENS_COMBO'] = df[\"SENT_TOKENS\"].map(lambda t: \" \".join(t))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "194ab1ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5581f7f65450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SENT_TOKENS_COMBO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'size'"
     ]
    }
   ],
   "source": [
    "sentences = df['SENT_TOKENS_COMBO'].map(lambda t: t.split()).values\n",
    "\n",
    "model = w2v.Word2Vec(size=200, min_count=5, workers=4, iter=5)\n",
    "\n",
    "model.build_vocab(sentences)\n",
    "\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)\n",
    "\n",
    "model.save('./model\\model.w2v')\n",
    "\n",
    "wv = model.wv\n",
    "\n",
    "vocab = model.wv.vocab\n",
    "\n",
    "ind2w = {i+1:w for i,w in enumerate(sorted(vocab))}\n",
    "\n",
    "PAD_CHAR = \"**PAD**\"\n",
    "\n",
    "def build_matrix(ind2w, wv):\n",
    "    W = np.zeros((len(ind2w)+1, len(wv.word_vec(wv.index2word[0])) ))\n",
    "    words = [PAD_CHAR]\n",
    "    W[0][:] = np.zeros(len(wv.word_vec(wv.index2word[0])))\n",
    "    for idx, word in ind2w.items():\n",
    "        if idx >= W.shape[0]:\n",
    "            break    \n",
    "        W[idx][:] = wv.word_vec(word)\n",
    "        words.append(word)\n",
    "    return W, words\n",
    "\n",
    "W, words = build_matrix(ind2w, wv)\n",
    "\n",
    "def save_embeddings(W, words, outfile):\n",
    "    with open(outfile, 'w') as o:\n",
    "        #pad token already included\n",
    "        for i in range(len(words)):\n",
    "            line = [words[i]]\n",
    "            line.extend([str(d) for d in W[i]])\n",
    "            o.write(\" \".join(line) + \"\\n\")\n",
    "\n",
    "outfile = './model\\model.embed'\n",
    "save_embeddings(W, words, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c34972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embed_file):\n",
    "    #also normalizes the embeddings\n",
    "    W = []\n",
    "    with open(embed_file) as ef:\n",
    "        for line in ef:\n",
    "            line = line.rstrip().split()\n",
    "            vec = np.array(line[1:]).astype(np.float)\n",
    "            vec = vec / float(np.linalg.norm(vec) + 1e-6)\n",
    "            W.append(vec)\n",
    "        #UNK embedding, gaussian randomly initialized \n",
    "        print(\"adding unk embedding\")\n",
    "        vec = np.random.randn(len(W[-1]))\n",
    "        vec = vec / float(np.linalg.norm(vec) + 1e-6)\n",
    "        W.append(vec)\n",
    "    W = np.array(W)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548992e0",
   "metadata": {},
   "source": [
    "### Number of missing HOPI sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "165ed5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes without HOPI sections: 1867\n"
     ]
    }
   ],
   "source": [
    "# REMOVE THIS SECTION\n",
    "\n",
    "# Detect history of present illness in text (n = 2641 records without HoPI data)\n",
    "df_hopi = df[df[\"HOPI\"] != \"\"].reset_index(drop = True)\n",
    "\n",
    "missing = df[df[\"HOPI\"] == \"\"].reset_index(drop = True)\n",
    "\n",
    "len(missing)\n",
    "\n",
    "# Should be 2641 records\n",
    "print(\"Notes without HOPI sections: \" + str(len(missing)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87147948",
   "metadata": {},
   "source": [
    "### Initialize Stanford Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d43fe6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL CAN BE REMOVED\n",
    "# Add the jar and model via their path (instead of setting environment variables):\n",
    "jar = root + 'stanford-postagger-full-2020-11-17/stanford-postagger.jar'\n",
    "model = root + 'stanford-postagger-full-2020-11-17/models/english-left3words-distsim.tagger'\n",
    "\n",
    "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
    "\n",
    "# Add other jars from Stanford directory\n",
    "stanford_dir = pos_tagger._stanford_jar.rpartition('/')[0]\n",
    "stanford_jars = find_jars_within_path(stanford_dir)\n",
    "pos_tagger._stanford_jar = ':'.join(stanford_jars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da236dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL WILL BE REMOVED \n",
    "# For testing out other possible HOPI section headers\n",
    "\n",
    "#PREOPERATIVE DIAGNOSIS (n = 6)\n",
    "#ADMISSION DIAGNOSIS(es) (n = 38)(n = 45)\n",
    "#ADMITTING DIAGNOSES (n = 7)\n",
    "#HOSPITAL COURSE\n",
    "#REASON FOR ADMISSION\n",
    "\n",
    "ms = missing[\"TEXT\"].map(lambda t: re.search(\"\\nHISTORY:\", t))\n",
    "m = missing[~ms.isna()].reset_index()\n",
    "\n",
    "cap = 138\n",
    "lw = 15\n",
    "lwlw = 12\n",
    "hpi = 2\n",
    "crs = 951\n",
    "print(len(m))\n",
    "#print(m[\"TEXT\"][1])\n",
    "\n",
    "#missing[\"TEXT\"].to_csv(root + \"no hopi.csv\"\n",
    "\n",
    "#df[\"HOPI\"][8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62eba9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation, non-characters, etc. \n",
    "df_hopi[\"HOPI\"] = df_hopi[\"HOPI\"].apply(lambda x: re.sub('\\[\\*\\*[^\\]]*\\*\\*\\]', '', x))\n",
    "df_hopi[\"HOPI\"] = df_hopi[\"HOPI\"].apply(lambda x: re.sub('<[^>]*>', '', x))\n",
    "df_hopi[\"HOPI\"] = df_hopi[\"HOPI\"].apply(lambda x: re.sub('[\\W]+', ' ', x))\n",
    "df_hopi[\"HOPI\"] = df_hopi[\"HOPI\"].apply(lambda x: re.sub(\"\\d+\", \" \", x))\n",
    "\n",
    "# Tokenize\n",
    "df_hopi['tokens'] = df_hopi[\"HOPI\"].map(lambda n: word_tokenize(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d96b2801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of HOPI sections >= 500 tokens: 1656\n"
     ]
    }
   ],
   "source": [
    "# REMOVE THIS CELL \n",
    "\n",
    "# Truncate records with more than 500 tokes (n = 1143)\n",
    "count = df_hopi['tokens'].map(lambda c: len(np.unique(c)))\n",
    "\n",
    "df_hopi[\"trunc\"] = df_hopi['tokens'].map(lambda c: np.unique(c)[0:500])\n",
    "\n",
    "print(\"Number of HOPI sections >= 500 tokens: \" + str(len(df_hopi[count>=500])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841b468",
   "metadata": {},
   "source": [
    "## Plot a histogram of the Number of tokens in each HoPI document, after data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b72313d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODIFY THIS CELL\n",
    "df[\"trunc_len\"] = df['SENT_TOKENS'].map(lambda c: len(c))\n",
    "\n",
    "plt.hist(df[\"trunc_len\"], np.arange(0, 501, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f07c2f",
   "metadata": {},
   "source": [
    "## Split data in train, valid, and test sets\n",
    "### training (38,588 records, 69.9%), validation (5536 records, 10.0%) and testing (11,048 records, 20.0%) folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9cc17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random split\n",
    "train, tst = sklearn.model_selection.train_test_split(df_hopi, test_size= 0.3, random_state=42)\n",
    "\n",
    "test, valid = sklearn.model_selection.train_test_split(tst, test_size= 0.33, random_state=42)\n",
    "\n",
    "train = train.reset_index(drop = True).drop([\"CATEGORY\", \"DESCRIPTION\"], axis = 1)\n",
    "test = test.reset_index(drop = True).drop([\"CATEGORY\", \"DESCRIPTION\"], axis = 1)\n",
    "valid = valid.reset_index(drop = True).drop([\"CATEGORY\", \"DESCRIPTION\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c530173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get percentage of data in each set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f8d07",
   "metadata": {},
   "source": [
    "## Count number of tokens in the training dataset (n = ~92,468 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "790c81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurence of tokens that are in the training dataset\n",
    "n = len(np.unique(np.concatenate(train[\"trunc\"].values)))\n",
    "occ = Counter(np.concatenate(train[\"trunc\"].values))\n",
    "             \n",
    "# Tokens that occur >= 5 times are in the study vocabulary (should be ~19,503)\n",
    "vocab = [k for k,v in occ.items() if v >= 5]\n",
    "len(vocab)\n",
    "\n",
    "# Assign a unique integer ID for each token in the study vocabulary \n",
    "vocab_lookup = dict(zip(vocab, np.arange(0, len(vocab), 1)))\n",
    "\n",
    "# Convert each HoPI document to a 1D array of integers using this index\n",
    "#df_hopi[\"trunc_idx\"] = df_hopi[\"trunc\"].map(lambda x: [vocab_lookup.get(i) for i in x if i in vocab_lookup.keys()])\n",
    "\n",
    "train[\"trunc_idx\"] =  train[\"trunc\"].map(lambda x: [vocab_lookup.get(i) for i in x if i in vocab_lookup.keys()])\n",
    "valid[\"trunc_idx\"] =  valid[\"trunc\"].map(lambda x: [vocab_lookup.get(i) for i in x if i in vocab_lookup.keys()])\n",
    "test[\"trunc_idx\"] =  test[\"trunc\"].map(lambda x: [vocab_lookup.get(i) for i in x if i in vocab_lookup.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180a12e",
   "metadata": {},
   "source": [
    "# Document representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04e11ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent clinical notes documents as TF-IDF representation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def tfidf(df):\n",
    "    pipe = Pipeline([('count', CountVectorizer(vocabulary = vocab, lowercase = False)),('tfid', TfidfTransformer(use_idf=True))]).fit(df[\"HOPI\"].values)\n",
    "    pipe['count'].transform(df[\"HOPI\"].values).toarray()\n",
    "    pipe['tfid'].idf_\n",
    "\n",
    "    return pipe.transform(df[\"HOPI\"].values)\n",
    "\n",
    "# Create sparse matrix of size number of docs x words in vocab\n",
    "tfidf_train = tfidf(train)\n",
    "tfidf_valid = tfidf(valid)\n",
    "tfidf_test = tfidf(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e46938b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean embedding representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2746c",
   "metadata": {},
   "source": [
    "# Label representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0afc9",
   "metadata": {},
   "source": [
    "### Identify the hierarchical labels for each icd9 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7305717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the main ICD9 code (they are ordered for importance)\n",
    "train[\"ICD_Main\"] = train['ICD9_CODE'].map(lambda x: x[0])\n",
    "valid[\"ICD_Main\"] = valid['ICD9_CODE'].map(lambda x: x[0])\n",
    "test[\"ICD_Main\"] = test['ICD9_CODE'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9714dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pyhealth library to find code hierarchy for the train, test, and valid datasets\n",
    "icd9cm = InnerMap.load(\"ICD9CM\")\n",
    "\n",
    "def define_levels(x):\n",
    "    lvls = []\n",
    "    for l in x: \n",
    "        lvls.append(icd9cm.lookup(l))\n",
    "    return lvls\n",
    "\n",
    "def drop_top(X):\n",
    "    if '001-999.99' in X:\n",
    "        X.remove('001-999.99')\n",
    "    return X\n",
    "\n",
    "def get_codes(df):\n",
    "    df['icd_desc'] = df['ICD_Main'].map(lambda x: icd9cm.lookup(x))\n",
    "    df['levels'] = df['ICD_Main'].map(lambda x:icd9cm.get_ancestors(x)[::-1])\n",
    "    df['levels'].map(lambda x: drop_top(x))\n",
    "    df['levels_desc'] = df['levels'].map(lambda x: define_levels(x))\n",
    "\n",
    "get_codes(train)\n",
    "get_codes(valid)\n",
    "get_codes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65bc18b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs = pd.concat([train, train['levels_desc'].apply(pd.Series)], axis = 1).drop(\"levels_desc\", axis = 1).rename(columns={0: \"y_l1\", 1: \"y_l2\", 2: \"y_l3\", 3: \"y_l4\" })\n",
    "valid_labs = pd.concat([valid, valid['levels_desc'].apply(pd.Series)], axis = 1).drop(\"levels_desc\", axis = 1).rename(columns={0: \"y_l1\", 1: \"y_l2\", 2: \"y_l3\", 3: \"y_l4\" })\n",
    "test_labs = pd.concat([test, test['levels_desc'].apply(pd.Series)], axis = 1).drop(\"levels_desc\", axis = 1).rename(columns={0: \"y_l1\", 1: \"y_l2\", 2: \"y_l3\", 3: \"y_l4\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e86b53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>HOPI</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trunc</th>\n",
       "      <th>trunc_len</th>\n",
       "      <th>trunc_idx</th>\n",
       "      <th>ICD_Main</th>\n",
       "      <th>icd_desc</th>\n",
       "      <th>levels</th>\n",
       "      <th>y_l1</th>\n",
       "      <th>y_l2</th>\n",
       "      <th>y_l3</th>\n",
       "      <th>y_l4</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144152</td>\n",
       "      <td>[56211, 56721, 5849, 51881, 0389, 99591, 5695,...</td>\n",
       "      <td>59347</td>\n",
       "      <td>Admission Date:  [**2145-1-16**]              ...</td>\n",
       "      <td>Ms Known is a   year old female who was trans...</td>\n",
       "      <td>[Ms, Known, is, a, year, old, female, who, was...</td>\n",
       "      <td>[A, ARF, At, CT, Chronic, HTN, Her, History, H...</td>\n",
       "      <td>123</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>56211</td>\n",
       "      <td>Diverticulitis of colon (without mention of he...</td>\n",
       "      <td>[520-579.99, 560-569.99, 562, 562.1]</td>\n",
       "      <td>DISEASES OF THE DIGESTIVE SYSTEM</td>\n",
       "      <td>OTHER DISEASES OF INTESTINES AND PERITONEUM</td>\n",
       "      <td>Diverticula of intestine</td>\n",
       "      <td>Diverticula of colon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117757</td>\n",
       "      <td>[4280, 4240, 4254, 5849, 486, 42789, 25000, 28...</td>\n",
       "      <td>25411</td>\n",
       "      <td>Admission Date:  [**2156-1-8**]              D...</td>\n",
       "      <td>Age yo male with pmhx significant for Type   ...</td>\n",
       "      <td>[Age, yo, male, with, pmhx, significant, for, ...</td>\n",
       "      <td>[Age, At, BP, BiPap, CHF, Diabetes, ED, EMS, H...</td>\n",
       "      <td>153</td>\n",
       "      <td>[121, 2, 122, 123, 124, 125, 126, 127, 128, 12...</td>\n",
       "      <td>4280</td>\n",
       "      <td>Congestive heart failure, unspecified</td>\n",
       "      <td>[390-459.99, 420-429.99, 428]</td>\n",
       "      <td>DISEASES OF THE CIRCULATORY SYSTEM</td>\n",
       "      <td>OTHER FORMS OF HEART DISEASE</td>\n",
       "      <td>Heart failure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118641</td>\n",
       "      <td>[57451, 0389, 99592, 5761, 34540, 5849, 5373, ...</td>\n",
       "      <td>80649</td>\n",
       "      <td>Admission Date:  [**2182-9-22**]              ...</td>\n",
       "      <td>M with CAD s p DES to LAD x   in   TIA s p C...</td>\n",
       "      <td>[M, with, CAD, s, p, DES, to, LAD, x, in, TIA,...</td>\n",
       "      <td>[ALT, AM, AP, AST, Also, BPs, BiPap, Bipap, Bl...</td>\n",
       "      <td>194</td>\n",
       "      <td>[248, 249, 250, 251, 252, 253, 123, 254, 255, ...</td>\n",
       "      <td>57451</td>\n",
       "      <td>Calculus of bile duct without mention of chole...</td>\n",
       "      <td>[520-579.99, 570-579.99, 574, 574.5]</td>\n",
       "      <td>DISEASES OF THE DIGESTIVE SYSTEM</td>\n",
       "      <td>OTHER DISEASES OF DIGESTIVE SYSTEM</td>\n",
       "      <td>Cholelithiasis</td>\n",
       "      <td>Calculus of bile duct without mention of chole...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151581</td>\n",
       "      <td>[2252, 73390, 3689]</td>\n",
       "      <td>92585</td>\n",
       "      <td>Admission Date:  [**2174-4-18**]              ...</td>\n",
       "      <td>This is a   year old female who presents in c...</td>\n",
       "      <td>[This, is, a, year, old, female, who, presents...</td>\n",
       "      <td>[Chiari, History, I, In, Knee, Malformation, M...</td>\n",
       "      <td>77</td>\n",
       "      <td>[386, 7, 387, 131, 388, 389, 14, 390, 21, 391,...</td>\n",
       "      <td>2252</td>\n",
       "      <td>Benign neoplasm of cerebral meninges</td>\n",
       "      <td>[140-239.99, 210-229.99, 225]</td>\n",
       "      <td>NEOPLASMS</td>\n",
       "      <td>BENIGN NEOPLASMS</td>\n",
       "      <td>Benign neoplasm of brain and other parts of ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157741</td>\n",
       "      <td>[51881, 9349, E911, 7802, 78009, 45829, 2767, ...</td>\n",
       "      <td>57751</td>\n",
       "      <td>Admission Date:  [**2161-5-8**]              D...</td>\n",
       "      <td>y o female w PMHx IDDM depression panic att...</td>\n",
       "      <td>[y, o, female, w, PMHx, IDDM, depression, pani...</td>\n",
       "      <td>[ABG, AST, BHC, BP, Bedside, CT, Center, Durin...</td>\n",
       "      <td>175</td>\n",
       "      <td>[436, 251, 122, 437, 3, 438, 439, 126, 440, 44...</td>\n",
       "      <td>51881</td>\n",
       "      <td>Acute respiratory failure</td>\n",
       "      <td>[460-519.99, 510-519.99, 518, 518.8]</td>\n",
       "      <td>DISEASES OF THE RESPIRATORY SYSTEM</td>\n",
       "      <td>OTHER DISEASES OF RESPIRATORY SYSTEM</td>\n",
       "      <td>Other diseases of lung</td>\n",
       "      <td>Other diseases of lung</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37308</th>\n",
       "      <td>121052</td>\n",
       "      <td>[E8788, E8497, 4589, 30503, 25000, 56984, 5621...</td>\n",
       "      <td>2554</td>\n",
       "      <td>Admission Date:  [**2148-3-21**]              ...</td>\n",
       "      <td>This is a   yo man with a history of Hep C Ci...</td>\n",
       "      <td>[This, is, a, yo, man, with, a, history, of, H...</td>\n",
       "      <td>[AM, Apparently, BM, BP, C, CP, Cirrhosis, ED,...</td>\n",
       "      <td>97</td>\n",
       "      <td>[249, 4949, 1392, 122, 713, 614, 1615, 126, 76...</td>\n",
       "      <td>E8788</td>\n",
       "      <td>Other specified surgical operations and proced...</td>\n",
       "      <td>[E000-E999.9, E878-E879.9, E878]</td>\n",
       "      <td>SUPPLEMENTARY CLASSIFICATION OF EXTERNAL CAUSE...</td>\n",
       "      <td>SURGICAL AND MEDICAL PROCEDURES AS THE CAUSE O...</td>\n",
       "      <td>Surgical operation and other surgical procedur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37309</th>\n",
       "      <td>183933</td>\n",
       "      <td>[5304, 5192, 486, 5780, 5185, 53085, 5303, 443...</td>\n",
       "      <td>23936</td>\n",
       "      <td>Admission Date:  [**2178-2-27**]              ...</td>\n",
       "      <td>The patient is a   y o male with a h o esopha...</td>\n",
       "      <td>[The, patient, is, a, y, o, male, with, a, h, ...</td>\n",
       "      <td>[CT, ED, NG, No, On, Over, The, There, a, adja...</td>\n",
       "      <td>117</td>\n",
       "      <td>[3, 126, 1624, 984, 137, 4591, 280, 393, 28, 6...</td>\n",
       "      <td>5304</td>\n",
       "      <td>Perforation of esophagus</td>\n",
       "      <td>[520-579.99, 530-539.99, 530]</td>\n",
       "      <td>DISEASES OF THE DIGESTIVE SYSTEM</td>\n",
       "      <td>DISEASES OF ESOPHAGUS, STOMACH, AND DUODENUM</td>\n",
       "      <td>Diseases of esophagus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37310</th>\n",
       "      <td>171661</td>\n",
       "      <td>[3968, 42731, 2875, 9992, 4168, 45182]</td>\n",
       "      <td>19410</td>\n",
       "      <td>Admission Date:  [**2150-3-10**]              ...</td>\n",
       "      <td>yo Chinese man who was recently diagnosed w...</td>\n",
       "      <td>[yo, Chinese, man, who, was, recently, diagnos...</td>\n",
       "      <td>[AR, AVR, Abd, Acetaminophen, Afebrile, Aspiri...</td>\n",
       "      <td>146</td>\n",
       "      <td>[2043, 1812, 3098, 2046, 2384, 1818, 3294, 181...</td>\n",
       "      <td>3968</td>\n",
       "      <td>Multiple involvement of mitral and aortic valves</td>\n",
       "      <td>[390-459.99, 393-398.99, 396]</td>\n",
       "      <td>DISEASES OF THE CIRCULATORY SYSTEM</td>\n",
       "      <td>CHRONIC RHEUMATIC HEART DISEASE</td>\n",
       "      <td>Diseases of mitral and aortic valves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37311</th>\n",
       "      <td>101598</td>\n",
       "      <td>[V3000, 76516, 77181, 769, 7793, 7742, 76525, ...</td>\n",
       "      <td>18202</td>\n",
       "      <td>Admission Date: [**2144-10-1**]        Dischar...</td>\n",
       "      <td>Baby Girl Known is a     gram product of a   ...</td>\n",
       "      <td>[Baby, Girl, Known, is, a, gram, product, of, ...</td>\n",
       "      <td>[Abdomen, Anus, At, B, Baby, Bilateral, Extrem...</td>\n",
       "      <td>114</td>\n",
       "      <td>[1813, 17092, 2, 1684, 1783, 2056, 2535, 1232,...</td>\n",
       "      <td>V3000</td>\n",
       "      <td>Single liveborn, born in hospital, delivered w...</td>\n",
       "      <td>[V01-V91.99, V30-V39.99, V30, V30.0]</td>\n",
       "      <td>SUPPLEMENTARY CLASSIFICATION OF FACTORS INFLUE...</td>\n",
       "      <td>LIVEBORN INFANTS ACCORDING TO TYPE OF BIRTH</td>\n",
       "      <td>Single liveborn</td>\n",
       "      <td>Single liveborn, born in hospital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37312</th>\n",
       "      <td>129545</td>\n",
       "      <td>[5070, 5191, 49121, 2860, 4370, 5780, 72210, 4...</td>\n",
       "      <td>11743</td>\n",
       "      <td>Admission Date:  [**2147-2-24**]       Dischar...</td>\n",
       "      <td>This is an   year old Caucasian male with a h...</td>\n",
       "      <td>[This, is, an, year, old, Caucasian, male, wit...</td>\n",
       "      <td>[ABG, AVM, Albuterol, At, Atrovent, CT, Caucas...</td>\n",
       "      <td>209</td>\n",
       "      <td>[436, 4465, 1189, 2, 8824, 3, 4482, 1041, 3072...</td>\n",
       "      <td>5070</td>\n",
       "      <td>Pneumonitis due to inhalation of food or vomitus</td>\n",
       "      <td>[460-519.99, 500-508.99, 507]</td>\n",
       "      <td>DISEASES OF THE RESPIRATORY SYSTEM</td>\n",
       "      <td>PNEUMOCONIOSES AND OTHER LUNG DISEASES DUE TO ...</td>\n",
       "      <td>Pneumonitis due to solids and liquids</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37313 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HADM_ID                                          ICD9_CODE  SUBJECT_ID  \\\n",
       "0       144152  [56211, 56721, 5849, 51881, 0389, 99591, 5695,...       59347   \n",
       "1       117757  [4280, 4240, 4254, 5849, 486, 42789, 25000, 28...       25411   \n",
       "2       118641  [57451, 0389, 99592, 5761, 34540, 5849, 5373, ...       80649   \n",
       "3       151581                                [2252, 73390, 3689]       92585   \n",
       "4       157741  [51881, 9349, E911, 7802, 78009, 45829, 2767, ...       57751   \n",
       "...        ...                                                ...         ...   \n",
       "37308   121052  [E8788, E8497, 4589, 30503, 25000, 56984, 5621...        2554   \n",
       "37309   183933  [5304, 5192, 486, 5780, 5185, 53085, 5303, 443...       23936   \n",
       "37310   171661             [3968, 42731, 2875, 9992, 4168, 45182]       19410   \n",
       "37311   101598  [V3000, 76516, 77181, 769, 7793, 7742, 76525, ...       18202   \n",
       "37312   129545  [5070, 5191, 49121, 2860, 4370, 5780, 72210, 4...       11743   \n",
       "\n",
       "                                                    TEXT  \\\n",
       "0      Admission Date:  [**2145-1-16**]              ...   \n",
       "1      Admission Date:  [**2156-1-8**]              D...   \n",
       "2      Admission Date:  [**2182-9-22**]              ...   \n",
       "3      Admission Date:  [**2174-4-18**]              ...   \n",
       "4      Admission Date:  [**2161-5-8**]              D...   \n",
       "...                                                  ...   \n",
       "37308  Admission Date:  [**2148-3-21**]              ...   \n",
       "37309  Admission Date:  [**2178-2-27**]              ...   \n",
       "37310  Admission Date:  [**2150-3-10**]              ...   \n",
       "37311  Admission Date: [**2144-10-1**]        Dischar...   \n",
       "37312  Admission Date:  [**2147-2-24**]       Dischar...   \n",
       "\n",
       "                                                    HOPI  \\\n",
       "0       Ms Known is a   year old female who was trans...   \n",
       "1       Age yo male with pmhx significant for Type   ...   \n",
       "2        M with CAD s p DES to LAD x   in   TIA s p C...   \n",
       "3       This is a   year old female who presents in c...   \n",
       "4         y o female w PMHx IDDM depression panic att...   \n",
       "...                                                  ...   \n",
       "37308   This is a   yo man with a history of Hep C Ci...   \n",
       "37309   The patient is a   y o male with a h o esopha...   \n",
       "37310     yo Chinese man who was recently diagnosed w...   \n",
       "37311   Baby Girl Known is a     gram product of a   ...   \n",
       "37312   This is an   year old Caucasian male with a h...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [Ms, Known, is, a, year, old, female, who, was...   \n",
       "1      [Age, yo, male, with, pmhx, significant, for, ...   \n",
       "2      [M, with, CAD, s, p, DES, to, LAD, x, in, TIA,...   \n",
       "3      [This, is, a, year, old, female, who, presents...   \n",
       "4      [y, o, female, w, PMHx, IDDM, depression, pani...   \n",
       "...                                                  ...   \n",
       "37308  [This, is, a, yo, man, with, a, history, of, H...   \n",
       "37309  [The, patient, is, a, y, o, male, with, a, h, ...   \n",
       "37310  [yo, Chinese, man, who, was, recently, diagnos...   \n",
       "37311  [Baby, Girl, Known, is, a, gram, product, of, ...   \n",
       "37312  [This, is, an, year, old, Caucasian, male, wit...   \n",
       "\n",
       "                                                   trunc  trunc_len  \\\n",
       "0      [A, ARF, At, CT, Chronic, HTN, Her, History, H...        123   \n",
       "1      [Age, At, BP, BiPap, CHF, Diabetes, ED, EMS, H...        153   \n",
       "2      [ALT, AM, AP, AST, Also, BPs, BiPap, Bipap, Bl...        194   \n",
       "3      [Chiari, History, I, In, Knee, Malformation, M...         77   \n",
       "4      [ABG, AST, BHC, BP, Bedside, CT, Center, Durin...        175   \n",
       "...                                                  ...        ...   \n",
       "37308  [AM, Apparently, BM, BP, C, CP, Cirrhosis, ED,...         97   \n",
       "37309  [CT, ED, NG, No, On, Over, The, There, a, adja...        117   \n",
       "37310  [AR, AVR, Abd, Acetaminophen, Afebrile, Aspiri...        146   \n",
       "37311  [Abdomen, Anus, At, B, Baby, Bilateral, Extrem...        114   \n",
       "37312  [ABG, AVM, Albuterol, At, Atrovent, CT, Caucas...        209   \n",
       "\n",
       "                                               trunc_idx ICD_Main  \\\n",
       "0      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...    56211   \n",
       "1      [121, 2, 122, 123, 124, 125, 126, 127, 128, 12...     4280   \n",
       "2      [248, 249, 250, 251, 252, 253, 123, 254, 255, ...    57451   \n",
       "3      [386, 7, 387, 131, 388, 389, 14, 390, 21, 391,...     2252   \n",
       "4      [436, 251, 122, 437, 3, 438, 439, 126, 440, 44...    51881   \n",
       "...                                                  ...      ...   \n",
       "37308  [249, 4949, 1392, 122, 713, 614, 1615, 126, 76...    E8788   \n",
       "37309  [3, 126, 1624, 984, 137, 4591, 280, 393, 28, 6...     5304   \n",
       "37310  [2043, 1812, 3098, 2046, 2384, 1818, 3294, 181...     3968   \n",
       "37311  [1813, 17092, 2, 1684, 1783, 2056, 2535, 1232,...    V3000   \n",
       "37312  [436, 4465, 1189, 2, 8824, 3, 4482, 1041, 3072...     5070   \n",
       "\n",
       "                                                icd_desc  \\\n",
       "0      Diverticulitis of colon (without mention of he...   \n",
       "1                  Congestive heart failure, unspecified   \n",
       "2      Calculus of bile duct without mention of chole...   \n",
       "3                   Benign neoplasm of cerebral meninges   \n",
       "4                              Acute respiratory failure   \n",
       "...                                                  ...   \n",
       "37308  Other specified surgical operations and proced...   \n",
       "37309                           Perforation of esophagus   \n",
       "37310   Multiple involvement of mitral and aortic valves   \n",
       "37311  Single liveborn, born in hospital, delivered w...   \n",
       "37312   Pneumonitis due to inhalation of food or vomitus   \n",
       "\n",
       "                                     levels  \\\n",
       "0      [520-579.99, 560-569.99, 562, 562.1]   \n",
       "1             [390-459.99, 420-429.99, 428]   \n",
       "2      [520-579.99, 570-579.99, 574, 574.5]   \n",
       "3             [140-239.99, 210-229.99, 225]   \n",
       "4      [460-519.99, 510-519.99, 518, 518.8]   \n",
       "...                                     ...   \n",
       "37308      [E000-E999.9, E878-E879.9, E878]   \n",
       "37309         [520-579.99, 530-539.99, 530]   \n",
       "37310         [390-459.99, 393-398.99, 396]   \n",
       "37311  [V01-V91.99, V30-V39.99, V30, V30.0]   \n",
       "37312         [460-519.99, 500-508.99, 507]   \n",
       "\n",
       "                                                    y_l1  \\\n",
       "0                       DISEASES OF THE DIGESTIVE SYSTEM   \n",
       "1                     DISEASES OF THE CIRCULATORY SYSTEM   \n",
       "2                       DISEASES OF THE DIGESTIVE SYSTEM   \n",
       "3                                              NEOPLASMS   \n",
       "4                     DISEASES OF THE RESPIRATORY SYSTEM   \n",
       "...                                                  ...   \n",
       "37308  SUPPLEMENTARY CLASSIFICATION OF EXTERNAL CAUSE...   \n",
       "37309                   DISEASES OF THE DIGESTIVE SYSTEM   \n",
       "37310                 DISEASES OF THE CIRCULATORY SYSTEM   \n",
       "37311  SUPPLEMENTARY CLASSIFICATION OF FACTORS INFLUE...   \n",
       "37312                 DISEASES OF THE RESPIRATORY SYSTEM   \n",
       "\n",
       "                                                    y_l2  \\\n",
       "0            OTHER DISEASES OF INTESTINES AND PERITONEUM   \n",
       "1                           OTHER FORMS OF HEART DISEASE   \n",
       "2                     OTHER DISEASES OF DIGESTIVE SYSTEM   \n",
       "3                                       BENIGN NEOPLASMS   \n",
       "4                   OTHER DISEASES OF RESPIRATORY SYSTEM   \n",
       "...                                                  ...   \n",
       "37308  SURGICAL AND MEDICAL PROCEDURES AS THE CAUSE O...   \n",
       "37309       DISEASES OF ESOPHAGUS, STOMACH, AND DUODENUM   \n",
       "37310                    CHRONIC RHEUMATIC HEART DISEASE   \n",
       "37311        LIVEBORN INFANTS ACCORDING TO TYPE OF BIRTH   \n",
       "37312  PNEUMOCONIOSES AND OTHER LUNG DISEASES DUE TO ...   \n",
       "\n",
       "                                                    y_l3  \\\n",
       "0                               Diverticula of intestine   \n",
       "1                                          Heart failure   \n",
       "2                                         Cholelithiasis   \n",
       "3      Benign neoplasm of brain and other parts of ne...   \n",
       "4                                 Other diseases of lung   \n",
       "...                                                  ...   \n",
       "37308  Surgical operation and other surgical procedur...   \n",
       "37309                              Diseases of esophagus   \n",
       "37310               Diseases of mitral and aortic valves   \n",
       "37311                                    Single liveborn   \n",
       "37312              Pneumonitis due to solids and liquids   \n",
       "\n",
       "                                                    y_l4    4  \n",
       "0                                   Diverticula of colon  NaN  \n",
       "1                                                    NaN  NaN  \n",
       "2      Calculus of bile duct without mention of chole...  NaN  \n",
       "3                                                    NaN  NaN  \n",
       "4                                 Other diseases of lung  NaN  \n",
       "...                                                  ...  ...  \n",
       "37308                                                NaN  NaN  \n",
       "37309                                                NaN  NaN  \n",
       "37310                                                NaN  NaN  \n",
       "37311                  Single liveborn, born in hospital  NaN  \n",
       "37312                                                NaN  NaN  \n",
       "\n",
       "[37313 rows x 17 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths at each icd hierarchy\n",
    "train_labs[['y_l1', 'y_l2', 'y_l3', 'y_l4']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00750564",
   "metadata": {},
   "source": [
    "### TFIDF-Atomic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0df4d0",
   "metadata": {},
   "source": [
    "#### TFIDF document weights were input into a multinomical logistic regression classifier in order to predict the 3 levels of icd hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32b285c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Logistic Regression from sklearn \n",
    "\n",
    "# L2 values to iterate over\n",
    "L2 = np.logspace(.01, 100, num = 50)\n",
    "\n",
    "# Multinomial Logistic Regression Model\n",
    "tfidf_atomic = LogisticRegression(multi_class = 'multinomial', penalty = 'l2', max_iter = 1500, solver = \"sag\", random_state = 42)\n",
    "\n",
    "\n",
    "#tfidf_atomic_L1 = tfidf.fit(tfidf_train, train['l1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe63853",
   "metadata": {},
   "source": [
    "### Mean-embedding representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8658d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57d4117a",
   "metadata": {},
   "source": [
    "### GRU representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7ce0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e62e6c49de2640afe301eb0b2acbb83744f5d70b682db4580c6d91865314c54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
